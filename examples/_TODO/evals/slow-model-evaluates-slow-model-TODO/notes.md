During production, use a fast model to generate responses while the stronger but slower model does evaluation in the background.

This works if the slower model is only checking a subset of the outputs.

This will add latency to a subset of the responses.
