- Use a non-agentic workflow first. Call an LLM to turn the user query into a search query, then use that to generate the response.
- Show statuses on the frontend using `data`
- Serper Search API
- Web scraping with Firecrawl
- File-system caching on external services
- TRY tracking sources used in frontend
- Write evals with modern information requested
- TRY playing with Top-K for best eval results
- TRY adding OCR for PDF's
- TRY writing our own crawler

---

Huggingface chat repo

Svelte app

3-4 different crawler implementations

One uses JSDom, one uses playwright, one uses Chrome locally, one uses puppeteer, Cheerio

---

With your own crawler implementation, you have full control - but full responsibility

---

If you get a 403, try looking at WebArchive

---

Pass the random text into smaller models to get the good stuff out

---

3-4 Google Search wrappers

SERPER

All the implementations are on hugging face

---

Bing is $1 per 1,000 queries
